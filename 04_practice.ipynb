{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dca894a4",
   "metadata": {},
   "source": [
    "\n",
    "# 감성 분석 모델\n",
    "\n",
    "**구 성**\n",
    "- 라벨: **긍정(1) / 부정(0)**\n",
    "- 5단계: 데이터 로드 → 전처리 → 모델 생성 → 학습 → 추론"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "af99f486",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow: 2.16.1\n"
     ]
    }
   ],
   "source": [
    "import os, re, unicodedata\n",
    "from typing import List\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Embedding, Dense, Dropout, LSTM, Bidirectional, GlobalMaxPooling1D\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "print(\"TensorFlow:\", tf.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7c08862c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 허용 문자 외는 공백으로 치환하는 정규식\n",
    "# 주의: raw string(r\"...\") 안에 \\s 는 한 번만 씁니다.\n",
    "KOREAN_KEEP_REGEX = re.compile(r'[^0-9A-Za-z가-힣ㄱ-ㅎㅏ-ㅣ\\s\\.,!?:;\\-\\(\\)\\'\"]')\n",
    "\n",
    "def normalize_text(s: str) -> str:\n",
    "    if not isinstance(s, str):\n",
    "        s = \"\" if s is None else str(s)\n",
    "    s = unicodedata.normalize(\"NFKC\", s)\n",
    "    s = KOREAN_KEEP_REGEX.sub(\" \", s)\n",
    "    s = re.sub(r\"\\s+\", \" \", s).strip()\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "fb9f2e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_text_columns(df: pd.DataFrame, text_cols: List[str]) -> List[str]:\n",
    "    use_cols = [c for c in text_cols if c in df.columns]\n",
    "    if not use_cols:\n",
    "        # '문장' 또는 '발화' 포함 컬럼 폴백\n",
    "        cand = [c for c in df.columns if (\"문장\" in c or \"발화\" in c)]\n",
    "        use_cols = cand[:3] if cand else [df.columns[0]]\n",
    "\n",
    "    texts = (\n",
    "        df[use_cols].fillna(\"\")\n",
    "                    .astype(str)\n",
    "                    .agg(\" [SEP] \".join, axis=1)\n",
    "                    .map(normalize_text)\n",
    "                    .tolist()\n",
    "    )\n",
    "    return texts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "613cdc11",
   "metadata": {},
   "source": [
    "## 1) 데이터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "637646a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파일 경로\n",
    "XLSX_PATH = \"./감성대화말뭉치(최종데이터)_Training.xlsx\"  # 필요 시 변경\n",
    "\n",
    "# 라벨/텍스트 컬럼\n",
    "# 기본은 '감정_대분류'를 사용하며, 없으면 '감정_분류'를 자동 폴백으로 사용\n",
    "PRIMARY_LABEL_CANDIDATES = [\"감정_대분류\"]\n",
    "TEXT_COLS = [\"사람문장1\", \"사람문장2\", \"사람문장3\"]\n",
    "\n",
    "# 토크나이저/모델 하이퍼파라미터\n",
    "NUM_WORDS = 30000\n",
    "MAX_LEN   = 96\n",
    "EMBED_DIM = 128\n",
    "RNN_UNITS = 128\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS     = 8\n",
    "PATIENCE   = 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f00ff55",
   "metadata": {},
   "source": [
    "## 3) 데이터 로드 & 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2652b032",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns: ['Unnamed: 0', '연령', '성별', '상황키워드', '신체질환', '감정_대분류', '감정_소분류', '사람문장1', '시스템문장1', '사람문장2', '시스템문장2', '사람문장3', '시스템문장3']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>연령</th>\n",
       "      <th>성별</th>\n",
       "      <th>상황키워드</th>\n",
       "      <th>신체질환</th>\n",
       "      <th>감정_대분류</th>\n",
       "      <th>감정_소분류</th>\n",
       "      <th>사람문장1</th>\n",
       "      <th>시스템문장1</th>\n",
       "      <th>사람문장2</th>\n",
       "      <th>시스템문장2</th>\n",
       "      <th>사람문장3</th>\n",
       "      <th>시스템문장3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>청년</td>\n",
       "      <td>여성</td>\n",
       "      <td>진로,취업,직장</td>\n",
       "      <td>해당없음</td>\n",
       "      <td>분노</td>\n",
       "      <td>노여워하는</td>\n",
       "      <td>일은 왜 해도 해도 끝이 없을까? 화가 난다.</td>\n",
       "      <td>많이 힘드시겠어요. 주위에 의논할 상대가 있나요?</td>\n",
       "      <td>그냥 내가 해결하는 게 나아. 남들한테 부담 주고 싶지도 않고.</td>\n",
       "      <td>혼자 해결하기로 했군요. 혼자서 해결하기 힘들면 주위에 의논할 사람을 찾아보세요.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>청년</td>\n",
       "      <td>여성</td>\n",
       "      <td>진로,취업,직장</td>\n",
       "      <td>해당없음</td>\n",
       "      <td>분노</td>\n",
       "      <td>노여워하는</td>\n",
       "      <td>이번 달에 또 급여가 깎였어! 물가는 오르는데 월급만 자꾸 깎이니까 너무 화가 나.</td>\n",
       "      <td>급여가 줄어 속상하시겠어요. 월급이 줄어든 것을 어떻게 보완하실 건가요?</td>\n",
       "      <td>최대한 지출을 억제해야겠어. 월급이 줄어들었으니 고정지출을 줄일 수밖에 없을 것 같아.</td>\n",
       "      <td>월급이 줄어든 만큼 소비를 줄일 계획이군요.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>청년</td>\n",
       "      <td>여성</td>\n",
       "      <td>진로,취업,직장</td>\n",
       "      <td>해당없음</td>\n",
       "      <td>분노</td>\n",
       "      <td>노여워하는</td>\n",
       "      <td>회사에 신입이 들어왔는데 말투가 거슬려. 그런 애를 매일 봐야 한다고 생각하니까 스...</td>\n",
       "      <td>회사 동료 때문에 스트레스를 많이 받는 것 같아요. 문제 해결을 위해 어떤 노력을 ...</td>\n",
       "      <td>잘 안 맞는 사람이랑 억지로 잘 지내는 것보단 조금은 거리를 두고 예의를 갖춰서 대...</td>\n",
       "      <td>스트레스받지 않기 위해선 인간관계에 있어 약간의 거리를 두는 게 좋겠군요.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  연령  성별     상황키워드  신체질환 감정_대분류 감정_소분류  \\\n",
       "0           1  청년  여성  진로,취업,직장  해당없음     분노  노여워하는   \n",
       "1           2  청년  여성  진로,취업,직장  해당없음     분노  노여워하는   \n",
       "2           3  청년  여성  진로,취업,직장  해당없음     분노  노여워하는   \n",
       "\n",
       "                                               사람문장1  \\\n",
       "0                          일은 왜 해도 해도 끝이 없을까? 화가 난다.   \n",
       "1     이번 달에 또 급여가 깎였어! 물가는 오르는데 월급만 자꾸 깎이니까 너무 화가 나.   \n",
       "2  회사에 신입이 들어왔는데 말투가 거슬려. 그런 애를 매일 봐야 한다고 생각하니까 스...   \n",
       "\n",
       "                                              시스템문장1  \\\n",
       "0                        많이 힘드시겠어요. 주위에 의논할 상대가 있나요?   \n",
       "1           급여가 줄어 속상하시겠어요. 월급이 줄어든 것을 어떻게 보완하실 건가요?   \n",
       "2  회사 동료 때문에 스트레스를 많이 받는 것 같아요. 문제 해결을 위해 어떤 노력을 ...   \n",
       "\n",
       "                                               사람문장2  \\\n",
       "0                그냥 내가 해결하는 게 나아. 남들한테 부담 주고 싶지도 않고.   \n",
       "1   최대한 지출을 억제해야겠어. 월급이 줄어들었으니 고정지출을 줄일 수밖에 없을 것 같아.   \n",
       "2  잘 안 맞는 사람이랑 억지로 잘 지내는 것보단 조금은 거리를 두고 예의를 갖춰서 대...   \n",
       "\n",
       "                                           시스템문장2 사람문장3 시스템문장3  \n",
       "0  혼자 해결하기로 했군요. 혼자서 해결하기 힘들면 주위에 의논할 사람을 찾아보세요.    NaN    NaN  \n",
       "1                        월급이 줄어든 만큼 소비를 줄일 계획이군요.   NaN    NaN  \n",
       "2       스트레스받지 않기 위해선 인간관계에 있어 약간의 거리를 두는 게 좋겠군요.   NaN    NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using label column: 감정_대분류\n"
     ]
    }
   ],
   "source": [
    "def read_excel(xlsx_path: str) -> pd.DataFrame:\n",
    "    assert os.path.exists(xlsx_path)\n",
    "    return pd.read_excel(xlsx_path)\n",
    "\n",
    "df = read_excel(XLSX_PATH)\n",
    "print(\"Columns:\", list(df.columns))\n",
    "display(df.head(3))\n",
    "\n",
    "# 라벨 컬럼 결정\n",
    "label_col = None\n",
    "for cand in PRIMARY_LABEL_CANDIDATES:\n",
    "    if cand in df.columns:\n",
    "        label_col = cand\n",
    "        break\n",
    "assert label_col is not None, f\"라벨 컬럼({PRIMARY_LABEL_CANDIDATES})을 데이터에서 찾을 수 없습니다.\"\n",
    "print(\"Using label column:\", label_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c971eba8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((51630, 96), (41304, 96), (5163, 96), (5163, 96), 0.11865194654270773)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 텍스트 결합\n",
    "texts = combine_text_columns(df, TEXT_COLS)\n",
    "\n",
    "# 이진 라벨: 대분류가 '기쁨'이면 1(긍정), 그 외는 0(부정)\n",
    "def to_binary_label(row) -> int:\n",
    "    major = str(row[label_col]) if pd.notna(row[label_col]) else \"\"\n",
    "    return 1 if \"기쁨\" in major else 0\n",
    "\n",
    "y = df.apply(to_binary_label, axis=1).astype(int).to_numpy()\n",
    "\n",
    "# 토크나이저 & 패딩\n",
    "tok = Tokenizer(num_words=NUM_WORDS, oov_token=\"<unk>\")\n",
    "tok.fit_on_texts(texts)\n",
    "X = pad_sequences(tok.texts_to_sequences(texts), maxlen=MAX_LEN, padding=\"post\", truncating=\"post\")\n",
    "\n",
    "# 분할\n",
    "n = len(X)\n",
    "idx = np.arange(n)\n",
    "np.random.seed(42); np.random.shuffle(idx)\n",
    "n_test = int(n * 0.1)\n",
    "n_val  = int(n * 0.1)\n",
    "test_idx = idx[:n_test]\n",
    "val_idx  = idx[n_test:n_test+n_val]\n",
    "train_idx = idx[n_test+n_val:]\n",
    "\n",
    "X_train, y_train = X[train_idx], y[train_idx]\n",
    "X_val,   y_val   = X[val_idx],   y[val_idx]\n",
    "X_test,  y_test  = X[test_idx],  y[test_idx]\n",
    "\n",
    "X.shape, X_train.shape, X_val.shape, X_test.shape, y.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac7b639",
   "metadata": {},
   "source": [
    "## 4) 모델 정의 및 생성 (BiLSTM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a5337aaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/nlp_env/lib/python3.12/site-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_5\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_5\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_ids (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ emb (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">3,840,000</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">263,168</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_max_pooling1d_5          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalMaxPooling1D</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_ids (\u001b[38;5;33mInputLayer\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m96\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ emb (\u001b[38;5;33mEmbedding\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m96\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │     \u001b[38;5;34m3,840,000\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_5 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m96\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │       \u001b[38;5;34m263,168\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_max_pooling1d_5          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalMaxPooling1D\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_10 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_10 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m32,896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_11 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_11 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m129\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,136,193</span> (15.78 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,136,193\u001b[0m (15.78 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,136,193</span> (15.78 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m4,136,193\u001b[0m (15.78 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def build_bilstm_binary(vocab_size: int, max_len: int,\n",
    "                        embed_dim: int = 128, rnn_units: int = 128, dropout: float = 0.3) -> Model:\n",
    "    inputs = Input(shape=(max_len,), name=\"input_ids\")\n",
    "    x = Embedding(input_dim=vocab_size, output_dim=embed_dim, input_length=max_len, name=\"emb\")(inputs)\n",
    "    x = Bidirectional(LSTM(rnn_units, return_sequences=True))(x)\n",
    "    x = GlobalMaxPooling1D()(x)\n",
    "    x = Dropout(dropout)(x)\n",
    "    x = Dense(rnn_units, activation=\"relu\")(x)\n",
    "    x = Dropout(dropout)(x)\n",
    "    outputs = Dense(1, activation=\"sigmoid\")(x)\n",
    "    model = Model(inputs, outputs)\n",
    "    model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "    return model\n",
    "\n",
    "vocab_size = min(NUM_WORDS, len(tok.word_index) + 1)\n",
    "model = build_bilstm_binary(vocab_size=vocab_size, max_len=MAX_LEN,\n",
    "                            embed_dim=EMBED_DIM, rnn_units=RNN_UNITS)\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13d0a0c8",
   "metadata": {},
   "source": [
    "## 5) 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "dec815be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "\u001b[1m646/646\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 137ms/step - accuracy: 0.9449 - loss: 0.1574 - val_accuracy: 0.9673 - val_loss: 0.0953\n",
      "Epoch 2/8\n",
      "\u001b[1m646/646\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 136ms/step - accuracy: 0.9847 - loss: 0.0476 - val_accuracy: 0.9671 - val_loss: 0.0936\n",
      "Epoch 3/8\n",
      "\u001b[1m646/646\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 137ms/step - accuracy: 0.9950 - loss: 0.0180 - val_accuracy: 0.9642 - val_loss: 0.1324\n",
      "Epoch 4/8\n",
      "\u001b[1m646/646\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 133ms/step - accuracy: 0.9971 - loss: 0.0083 - val_accuracy: 0.9640 - val_loss: 0.1910\n",
      "Test Acc: 0.9655 | Test Loss: 0.0996\n"
     ]
    }
   ],
   "source": [
    "callbacks = [EarlyStopping(monitor=\"val_loss\", patience=PATIENCE, restore_best_weights=True)]\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"Test Acc: {test_acc:.4f} | Test Loss: {test_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5843781f",
   "metadata": {},
   "source": [
    "## 6) 추론"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "36a90385",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>입력 문장</th>\n",
       "      <th>긍정 확률</th>\n",
       "      <th>판정</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>오늘 너무 화나는 일이 있었어</td>\n",
       "      <td>0.351</td>\n",
       "      <td>부정</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>기분 최고야 너무 행복해</td>\n",
       "      <td>0.997</td>\n",
       "      <td>긍정</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>그냥 마음이 허하고 슬프다</td>\n",
       "      <td>0.063</td>\n",
       "      <td>부정</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              입력 문장  긍정 확률  판정\n",
       "0  오늘 너무 화나는 일이 있었어  0.351  부정\n",
       "1     기분 최고야 너무 행복해  0.997  긍정\n",
       "2    그냥 마음이 허하고 슬프다  0.063  부정"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def predict_proba(text_list: List[str], threshold: float = 0.5) -> pd.DataFrame:\n",
    "    texts_norm = [normalize_text(t) for t in text_list]\n",
    "    Xp = pad_sequences(tok.texts_to_sequences(texts_norm), maxlen=MAX_LEN, padding=\"post\", truncating=\"post\")\n",
    "    probs = model.predict(Xp, verbose=0).reshape(-1)\n",
    "    preds = (probs >= threshold).astype(int)\n",
    "    label_map = {0: \"부정\", 1: \"긍정\"}\n",
    "\n",
    "    df_out = pd.DataFrame({\n",
    "        \"입력 문장\": text_list,\n",
    "        \"긍정 확률\": probs.round(3),\n",
    "        \"판정\": [label_map[int(lbl)] for lbl in preds]\n",
    "    })\n",
    "    return df_out\n",
    "\n",
    "\n",
    "sentence = [\"오늘 너무 화나는 일이 있었어\", \"기분 최고야 너무 행복해\", \"그냥 마음이 허하고 슬프다\"]\n",
    "predict_proba(sentence)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
